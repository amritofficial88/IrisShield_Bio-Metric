{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "Install Requirements"
      },
      "outputs": [],
      "source": "!pip install -r requirements.txt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from skimage.util import view_as_blocks\nfrom utils import preprocess, find_best_match, select_image_from_dataset, display_images, show_details\nimport cv2\nimport glob\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport sys\nimport time"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "Features.py"
      },
      "outputs": [],
      "source": "# Global variable for gamma correction\ngamma = 0.32\n\n# Function to convert polar coordinates to Cartesian coordinates\ndef polar2cart(r, x0, y0, theta):\n    x = int(x0 + r * math.cos(theta))\n    y = int(y0 + r * math.sin(theta))\n    return x, y\n\n# Gamma correction function\ndef gammaCorrection(image):\n    lookUpTable = np.empty((1,256), np.uint8)\n    for i in range(256):\n        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255) \n    res = cv2.LUT(image, lookUpTable)\n    return res\n\n# Unravel iris function to generate normalized iris\ndef unravel_iris(img, xp, yp, rp, xi, yi, ri, phase_width=300, iris_width=150):\n    if img.ndim > 2:\n        img = img[:, :, 0].copy()\n    iris = np.zeros((iris_width, phase_width))\n    theta = np.linspace(0, 2 * np.pi, phase_width)\n\n    # Generate iris by calculating pixel values for each phase\n    for i in range(phase_width):\n        begin = polar2cart(rp, xp, yp, theta[i])\n        end = polar2cart(ri, xi, yi, theta[i])\n        xspace = np.linspace(begin[0], end[0], iris_width)\n        yspace = np.linspace(begin[1], end[1], iris_width)\n        iris[:, i] = [255 - img[int(y), int(x)] if 0 <= int(x) < img.shape[1] and 0 <= int(y) < img.shape[0] else 0\n                      for x, y in zip(xspace, yspace)]\n    return iris\n\n# 2D Gabor wavelets equation\ndef gabor(rho, phi, w, theta0, r0, alpha, beta):\n    return np.exp(-w * 1j * (theta0 - phi)) * np.exp(-(rho - r0) ** 2 / alpha ** 2) * np.exp(-(-phi + theta0) ** 2 / beta ** 2)\n\n# Applying 2D Gabor wavelets on the image\ndef gabor_convolve(img, w, alpha, beta):\n    rho = np.array([np.linspace(0, 1, img.shape[0]) for i in range(img.shape[1])]).T\n    x = np.linspace(0, 1, img.shape[0])\n    y = np.linspace(-np.pi, np.pi, img.shape[1])\n    xx, yy = np.meshgrid(x, y)\n    return rho * img * np.real(gabor(xx, yy, w, 0, 0, alpha, beta).T), \\\n           rho * img * np.imag(gabor(xx, yy, w, 0, 0, alpha, beta).T)\n\n# Iris encoding function\ndef iris_encode(img, dr=15, dtheta=15, alpha=0.4):\n    mask = view_as_blocks(np.logical_and(20 < img, img < 255), (dr, dtheta))\n    norm_iris = (img - img.mean()) / img.std()\n    patches = view_as_blocks(norm_iris, (dr, dtheta))\n    code = np.zeros((patches.shape[0] * 3, patches.shape[1] * 2))\n    code_mask = np.zeros((patches.shape[0] * 3, patches.shape[1] * 2))\n    \n    # Encode iris features using 2D Gabor wavelets\n    for i, row in enumerate(patches):\n        for j, p in enumerate(row):\n            for k, w in enumerate([8, 16, 32]):\n                wavelet = gabor_convolve(p, w, alpha, 1 / alpha)\n                code[3 * i + k, 2 * j] = np.sum(wavelet[0])\n                code[3 * i + k, 2 * j + 1] = np.sum(wavelet[1])\n                code_mask[3 * i + k, 2 * j] = code_mask[3 * i + k, 2 * j + 1] = \\\n                    1 if mask[i, j].sum() > dr * dtheta * 3 / 4 else 0\n    code[code >= 0] = 1\n    code[code < 0] = 0\n    return code, code_mask\n\n# Preprocess function to convert image to grayscale and apply Median Blur filter\ndef preprocess(image):\n    img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return cv2.medianBlur(img, 5)\n\n# Function to find pupil using Hough Circle Transform\ndef find_pupil_hough(img):\n    circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20,\n                               param1=60, param2=30, minRadius=1, maxRadius=40)\n    if circles is not None:\n        circles = np.uint16(np.around(circles))\n        return circles[0, 0][0], circles[0, 0][1], circles[0, 0][2]\n    else:\n        return 0, 0, 0\n\n# Function to find iris using Hough Circle Transform\ndef find_iris_hough(img):\n    circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20,\n                               param1=60, param2=30, minRadius=20, maxRadius=100)\n    if circles is not None: \n        circles = np.uint16(np.around(circles))\n        return circles[0, 0][0], circles[0, 0][1], circles[0, 0][2] \n    else:\n        return 0, 0, 0\n\n# Function to compare iris codes\ndef compare_codes(a, b, mask_a, mask_b):\n    return np.sum(np.remainder(a + b, 2) * mask_a * mask_b) / np.sum(mask_a * mask_b)\n\n# Function to encode iris features of an image\ndef encode_photo(image):\n    src=gammaCorrection(image)\n    newImage = src.copy()\n    img = preprocess(image)\n    img1 = preprocess(newImage)\n    \n    x, y, r = find_pupil_hough(img1)\n    x_iris, y_iris, r_iris = find_iris_hough(img)\n    \n    iris = unravel_iris(image, x, y, r, x_iris, y_iris, r_iris)\n    return iris_encode(iris)\n\n\n# Function to select an image from the dataset for matching\ndef select_image_from_dataset(dataset_folder):\n    individual_id = input(\"Enter individual ID (001-108): \").zfill(3)\n    session_id = input(\"Enter session ID (1-2): \")\n    image_id = input(\"Enter image ID (1-3 for session 1, 1-4 for session 2): \")\n\n    if session_id == '1' and not (1 <= int(image_id) <= 3):\n        print(\"Error: Session 1 only accepts images 1 to 3.\")\n        return None, None\n    elif session_id == '2' and not (1 <= int(image_id) <= 4):\n        print(\"Error: Session 2 only accepts images 1 to 4.\")\n        return None, None\n\n    image_path = os.path.join(dataset_folder, f\"{individual_id}_{session_id}_{image_id}.jpg\")\n    if not os.path.exists(image_path):\n        print(\"Image not found. Please make sure the individual ID, session ID, and image ID are correct.\")\n        return None, None\n    \n    print(f\"Selected image: {image_path}\")\n    image = cv2.imread(image_path)\n    return image, individual_id, session_id\n\n# Function to display a list of images\ndef display_images(image_list):\n    for i, img in enumerate(image_list):\n        cv2.imshow(f\"Image {i+1}\", img)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\n\n# Function to find the best match in the dataset for a query image\ndef find_best_match(dataset_folder, query_image):\n    best_similarity = 1.0\n    best_match_id = None\n    \n    for filename in os.listdir(dataset_folder):\n        if filename.endswith(\".jpg\"):\n            filepath = os.path.join(dataset_folder, filename)\n            print(f\"Processing image: {filename}\")\n            dataset_image = cv2.imread(filepath)\n            \n            # Encode iris features\n            query_code, query_mask = encode_photo(query_image)\n            dataset_code, dataset_mask = encode_photo(dataset_image)\n            \n            # Compare iris codes\n            similarity = compare_codes(query_code, dataset_code, query_mask, dataset_mask)\n            print(f\"Similarity with {filename}: {similarity}\")\n            \n            if similarity == 0:\n                best_match_id = filename[:3]\n                best_similarity = similarity\n                break\n            \n            if similarity < best_similarity:\n                best_similarity = similarity\n                best_match_id = filename[:3]  # Extract individual ID from filename\n\n    return best_match_id, best_similarity\n\n# Function to display segmentation and normalization process details\ndef show_details(image):\n    src = gammaCorrection(image)\n    newImage = src.copy()\n    img = preprocess(image)\n    img1 = preprocess(newImage)\n\n    x, y, r = find_pupil_hough(img1)\n    x_iris, y_iris, r_iris = find_iris_hough(img)\n\n    iris = unravel_iris(image, x, y, r, x_iris, y_iris, r_iris)\n    cv2.circle(image, (x, y), r, (255, 0, 0), 3)\n    cv2.circle(image, (x, y), 2, (255, 0, 0), 2)\n    cv2.circle(image, (x_iris, y_iris), r_iris, (0, 255, 0), 3)\n    cv2.circle(image, (x_iris, y_iris), 2, (0, 255, 0), 2)\n\n    f, axes = plt.subplots(2, 2, figsize=(8, 8))\n    axes[0, 0].imshow(image, cmap=plt.cm.gray)\n    axes[0, 0].set_title('Segmentation process')\n    axes[0, 1].imshow(iris, cmap=plt.cm.gray)\n    axes[0, 1].set_title('Normalization process')\n\n    code, mask = iris_encode(iris)\n    axes[1, 0].imshow(iris, cmap=plt.cm.gray)\n    axes[1, 0].set_title('Normalization process')\n    axes[1, 1].imshow(mask, cmap=plt.cm.gray, interpolation='none')\n    axes[1, 1].set_title('Mask code')\n\n    cv2.circle(image, (x, y), r, (255, 255, 0), 2)\n    cv2.circle(image, (x_iris, y_iris), r_iris, (0, 255, 0), 2)\n\n    plt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "Hero.py"
      },
      "outputs": [],
      "source": "# Main function\nif __name__ == '__main__':\n    dataset_folder = r'..\\Iris-Recognition\\dataset'\n    \n    print(\"Please select an image from the dataset for matching:\")\n    query_image, individual_id, session_id = select_image_from_dataset(dataset_folder)\n    \n    if query_image is not None:\n        start_time = time.time()  # Start measuring time\n        \n        best_match_id, similarity = find_best_match(dataset_folder, query_image)\n        \n        end_time = time.time()  # Stop measuring time\n        execution_time = end_time - start_time\n\n        # Load and display the input image\n        query_images = [query_image]\n        print(\"Displaying input image:\")\n        display_images(query_images)\n        \n        print(\"Best match found:\")\n        print(f\"Individual ID: {best_match_id}\")\n        print(f\"Similarity: {similarity}\")\n        print(f\"Execution Time: {execution_time} seconds\")\n        \n        \n        # Display segmentation and normalization process details for the input image\n        print(\"Displaying segmentation and normalization process details for the input image:\")\n        show_details(query_image)\n\n        if best_match_id is not None:\n            print(f\"Displaying all images of the matched individual {best_match_id}:\")\n            individual_images = []\n            for filename in os.listdir(dataset_folder):\n                if filename.startswith(best_match_id) and filename.endswith(\".jpg\"):\n                    filepath = os.path.join(dataset_folder, filename)\n                    img = cv2.imread(filepath)\n                    individual_images.append(img)\n            display_images(individual_images)\n\n        # Close all OpenCV windows after processing\n        cv2.destroyAllWindows()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}